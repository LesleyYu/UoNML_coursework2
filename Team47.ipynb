{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import missingno as msno\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pCR (outcome)</th>\n",
       "      <th>RelapseFreeSurvival (outcome)</th>\n",
       "      <th>Age</th>\n",
       "      <th>ER</th>\n",
       "      <th>PgR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>TrippleNegative</th>\n",
       "      <th>ChemoGrade</th>\n",
       "      <th>Proliferation</th>\n",
       "      <th>HistologyType</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_ngtdm_Busyness</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.375126</td>\n",
       "      <td>3.325332</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>3880771.500</td>\n",
       "      <td>473.464852</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>3.032144</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>2372009.744</td>\n",
       "      <td>59.459710</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>2.485848</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>1540027.421</td>\n",
       "      <td>33.935384</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>2.606255</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>6936740.794</td>\n",
       "      <td>46.859265</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.004543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>2.809279</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>1265399.054</td>\n",
       "      <td>39.621023</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  HER2  \\\n",
       "0              1                          144.0  41.0   0  0.0   0.0   \n",
       "1              0                          142.0  39.0   1  1.0   0.0   \n",
       "2              1                          135.0  31.0   0  0.0   0.0   \n",
       "3              0                           12.0  35.0   0  0.0   0.0   \n",
       "4              0                          109.0  61.0   1  0.0   0.0   \n",
       "\n",
       "   TrippleNegative  ChemoGrade  Proliferation  HistologyType  ...  \\\n",
       "0              1.0           3              3              1  ...   \n",
       "1              0.0           3              3              1  ...   \n",
       "2              1.0           2              1              1  ...   \n",
       "3              1.0           3              3              1  ...   \n",
       "4              0.0           2              1              1  ...   \n",
       "\n",
       "   original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                       0.517172   \n",
       "1                                       0.444391   \n",
       "2                                       0.534549   \n",
       "3                                       0.506185   \n",
       "4                                       0.462282   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                      0.375126                    3.325332   \n",
       "1                                      0.444391                    3.032144   \n",
       "2                                      0.534549                    2.485848   \n",
       "3                                      0.506185                    2.606255   \n",
       "4                                      0.462282                    2.809279   \n",
       "\n",
       "   original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n",
       "0                       0.002314                  3880771.500   \n",
       "1                       0.005612                  2372009.744   \n",
       "2                       0.006752                  1540027.421   \n",
       "3                       0.003755                  6936740.794   \n",
       "4                       0.006521                  1265399.054   \n",
       "\n",
       "   original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
       "0               473.464852                   0.000768   \n",
       "1                59.459710                   0.004383   \n",
       "2                33.935384                   0.007584   \n",
       "3                46.859265                   0.005424   \n",
       "4                39.621023                   0.006585   \n",
       "\n",
       "   original_ngtdm_Complexity  original_ngtdm_Contrast  original_ngtdm_Strength  \n",
       "0                   0.182615                 0.030508                 0.000758  \n",
       "1                   0.032012                 0.001006                 0.003685  \n",
       "2                   0.024062                 0.000529                 0.006447  \n",
       "3                   0.013707                 0.000178                 0.004543  \n",
       "4                   0.034148                 0.001083                 0.005626  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = pd.read_excel(\"trainDataset.xls\")\n",
    "dataFrame.drop(\"ID\", axis=1 ,inplace=True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont need to convert our data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      299\n",
       "1       96\n",
       "999      5\n",
       "Name: pCR (outcome), dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataFrame['pCR (outcome)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "categoricalTitles = ['pCR (outcome)','ER','PgR','HER2','TrippleNegative','ChemoGrade','Proliferation','HistologyType','LNStatus','TumourStage']\n",
    "for c in dataFrame.columns:\n",
    "    if c in categoricalTitles:\n",
    "        continue\n",
    "    q1Pos = 0.1\n",
    "    q3Pos = 0.9\n",
    "    q1=dataFrame[c].quantile(q1Pos)\n",
    "    q3=dataFrame[c].quantile(q3Pos)\n",
    "    IQR=q3-q1\n",
    "    upper_limit = q3+1.5*IQR\n",
    "    lower_limit = q1-1.5*IQR\n",
    "    outliers = dataFrame[c][((dataFrame[c]<(q1-1.5*IQR)) | (dataFrame[c]>(q3+1.5*IQR)))]\n",
    "    \n",
    "    dataFrame[c] = dataFrame[c].apply(lambda x : np.where(x > upper_limit, np.nan, np.where(x < lower_limit, np.nan, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nones:  434\n"
     ]
    }
   ],
   "source": [
    "dataFrame = dataFrame.replace(999, np.nan)\n",
    "print(\"Nones: \",dataFrame.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7e2dbbf88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_cols = dataFrame.columns[dataFrame.isnull().any()]\n",
    "msno.matrix(dataFrame[null_cols])#white is missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN for missing value replacement</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn imputer\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "model = RandomForestClassifier(ccp_alpha= 0.014, random_state = 23, n_estimators = 441, min_samples_split = 8, max_features = 'log2', max_depth = 20, criterion = 'entropy')\n",
    "bestNum = count = bestScore = 0\n",
    "while count < 30:\n",
    "    temp = random.randint(3, 65)\n",
    "    imputer = KNNImputer(n_neighbors=temp)\n",
    "\n",
    "    result = imputer.fit_transform(dataFrame)\n",
    "    nonNulldataFrame = pd.DataFrame(result, columns= dataFrame.columns)#non null whole data set\n",
    "    nonNulldataFrameBackUp = nonNulldataFrame\n",
    "    categoricalTitles = ['pCR (outcome)','ER','PgR','HER2','TrippleNegative','ChemoGrade','Proliferation','HistologyType','LNStatus','TumourStage']\n",
    "    nonNulldataFrame = nonNulldataFrame[categoricalTitles].apply(lambda x: round(x))#for all categorical data, do round function\n",
    "    nonNulldataFrameBackUp = nonNulldataFrameBackUp.drop(categoricalTitles, axis=1)\n",
    "    nonNulldataFrame = pd.concat([nonNulldataFrame, nonNulldataFrameBackUp], axis=1)\n",
    "    #checking for missing\n",
    "    #print(nonNulldataFrame.isnull().sum().sum())\n",
    "    \n",
    "    \n",
    "    #normalize Xs of non null data frame\n",
    "    standardScaler = preprocessing.StandardScaler()\n",
    "    normalizedXs = standardScaler.fit_transform(\n",
    "    nonNulldataFrame.drop([\"pCR (outcome)\",\"RelapseFreeSurvival (outcome)\"], axis=1))\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(\n",
    "        normalizedXs, \n",
    "        nonNulldataFrame[\"pCR (outcome)\"], \n",
    "        test_size=0.2,\n",
    "        random_state=1, \n",
    "        stratify=nonNulldataFrame[\"pCR (outcome)\"])\n",
    "    model.fit(Xs_train, y_train)\n",
    "    score = metrics.accuracy_score(y_test, model.predict(Xs_test))\n",
    "    if score > bestScore:\n",
    "        bestScore = score\n",
    "        bestNum = temp\n",
    "    count = count + 1\n",
    "\n",
    "#'shrinking': False, 'random_state': 18, 'kernel': 'rbf', 'gamma': 1000.0, 'degree': 36, 'C': 10000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModelOverAll = None\n",
    "performance = 0\n",
    "isKeras = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "0.7875\n"
     ]
    }
   ],
   "source": [
    "print(bestNum)\n",
    "print(bestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=bestNum)\n",
    "\n",
    "result = imputer.fit_transform(dataFrame)\n",
    "nonNulldataFrame = pd.DataFrame(result, columns= dataFrame.columns)#non null whole data set\n",
    "nonNulldataFrameBackUp = nonNulldataFrame\n",
    "categoricalTitles = ['pCR (outcome)','ER','PgR','HER2','TrippleNegative','ChemoGrade','Proliferation','HistologyType','LNStatus','TumourStage']\n",
    "nonNulldataFrame = nonNulldataFrame[categoricalTitles].apply(lambda x: round(x))#for all categorical data, do round function\n",
    "nonNulldataFrameBackUp = nonNulldataFrameBackUp.drop(categoricalTitles, axis=1)\n",
    "nonNulldataFrame = pd.concat([nonNulldataFrame, nonNulldataFrameBackUp], axis=1)\n",
    "#checking for missing\n",
    "print(nonNulldataFrame.isnull().sum().sum())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#normalize Xs of non null data frame\n",
    "standardScaler = preprocessing.StandardScaler()\n",
    "normalizedXs = standardScaler.fit_transform(\n",
    "    nonNulldataFrame.drop([\"pCR (outcome)\",\"RelapseFreeSurvival (outcome)\"], axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestFeatureSelectionModel = ReliefF(n_features_to_select=75, n_neighbors=87, n_jobs= -1)\n",
    "#XsAfterFeatureSelection = bestFeatureSelectionModel.fit_transform(\n",
    "#            normalizedXs,\n",
    "#            np.array(nonNulldataFrame[\"pCR (outcome)\"]))\n",
    "#Xs_train, Xs_test, y_train, y_test = train_test_split(\n",
    "#        XsAfterFeatureSelection, \n",
    "#        nonNulldataFrame[\"pCR (outcome)\"], \n",
    "#        test_size=0.2,\n",
    "#        random_state=1, \n",
    "#        stratify=nonNulldataFrame[\"pCR (outcome)\"])\n",
    "#model = models[1]\n",
    "#model.fit(Xs_train, y_train)\n",
    "#print(\"after fit\")\n",
    "    \n",
    "#score = metrics.accuracy_score(y_test, model.predict(Xs_test))\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th Try: 78.75%\n",
      "0 th Try: 78.75%\n",
      "0 th Try: 81.25%\n",
      "1 th Try: 81.25%\n",
      "2 th Try: 81.25%\n",
      "3 th Try: 81.25%\n",
      "4 th Try: 81.25%\n",
      "5 th Try: 81.25%\n",
      "6 th Try: 81.25%\n",
      "7 th Try: 81.25%\n",
      "8 th Try: 81.25%\n",
      "9 th Try: 81.25%\n",
      "10 th Try: 81.25%\n",
      "11 th Try: 81.25%\n",
      "12 th Try: 81.25%\n",
      "13 th Try: 81.25%\n",
      "14 th Try: 81.25%\n",
      "15 th Try: 81.25%\n",
      "16 th Try: 81.25%\n",
      "17 th Try: 81.25%\n",
      "18 th Try: 81.25%\n",
      "19 th Try: 81.25%\n",
      "Accuracy with Best Features: 81.25%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from skrebate import ReliefF\n",
    "import random\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PyImpetus import PPIMBC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "models = [SVC(shrinking = True, random_state = 31, kernel = 'rbf', gamma = 0.01, degree = 25, C = 0.1),\n",
    "          RandomForestClassifier(ccp_alpha= 0.014, random_state = 23, n_estimators = 441, min_samples_split = 8, max_features = 'log2', max_depth = 20, criterion = 'entropy'),\n",
    "          MLPClassifier(max_iter= 2000,  solver = 'sgd',  random_state = 15, learning_rate = 'constant', hidden_layer_sizes = (65, 29), alpha = 0.1, activation = 'tanh')]  \n",
    "bestFeatureNum = bestneighborNum =  count = 0\n",
    "bestScore = 0\n",
    "bestFeatureSelectionModel = None\n",
    "finalType = 0\n",
    "while count < 20 :\n",
    "    type = random.randint(0,2)\n",
    "    if type < 2:\n",
    "        featureNum = random.randint(10,90)\n",
    "        neighborNum = random.randint(10,90)\n",
    "        if type == 0:\n",
    "            featureSelectionModel = ReliefF(n_features_to_select=featureNum, n_neighbors=neighborNum, n_jobs= -1)\n",
    "        else:\n",
    "            featureSelectionModel = PPIMBC(LogisticRegression(random_state=27, max_iter=1000, class_weight=\"balanced\"), cv=0, num_simul=20, simul_type=0,simul_size=0.2, sig_test_type=\"non-parametric\", random_state=27, verbose=0, p_val_thresh=0.05)\n",
    "                            \n",
    "        XsAfterFeatureSelection = featureSelectionModel.fit_transform(\n",
    "            normalizedXs,\n",
    "            np.array(nonNulldataFrame[\"pCR (outcome)\"]))\n",
    "    else:\n",
    "        \n",
    "        lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(normalizedXs, np.array(nonNulldataFrame[\"pCR (outcome)\"]))\n",
    "        featureSelectionModel = SelectFromModel(lsvc, prefit=True)\n",
    "        XsAfterFeatureSelection = featureSelectionModel.transform(normalizedXs)\n",
    "\n",
    "    #split data up\n",
    "    \n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(\n",
    "        XsAfterFeatureSelection, \n",
    "        nonNulldataFrame[\"pCR (outcome)\"], \n",
    "        test_size=0.2,\n",
    "        random_state=1, \n",
    "        stratify=nonNulldataFrame[\"pCR (outcome)\"])\n",
    "    \n",
    "    #print(\"before fit\")\n",
    "    model = models[random.randint(0,2)]\n",
    "    model.fit(Xs_train, y_train)\n",
    "    #print(\"after fit\")\n",
    "    \n",
    "    score = metrics.accuracy_score(y_test, model.predict(Xs_test))\n",
    "    \n",
    "    if score > bestScore :\n",
    "        count = 0\n",
    "        bestScore = score\n",
    "        bestFeatureSelectionModel  = featureSelectionModel\n",
    "        finalType = type\n",
    "    print(\"%d %s: %.2f%%\" % (count ,\"th Try\", bestScore*100))\n",
    "    if bestScore >= 0.8:\n",
    "        count = count + 1\n",
    "\n",
    "print(\"%s: %.2f%%\" % (\"Accuracy with Best Features\", bestScore*100))\n",
    "\n",
    "\n",
    "#after feature selection split the data\n",
    "if finalType < 2:\n",
    "    XsAfterFeatureSelection = bestFeatureSelectionModel.fit_transform(\n",
    "            normalizedXs,\n",
    "            np.array(nonNulldataFrame[\"pCR (outcome)\"]))\n",
    "else:\n",
    "    XsAfterFeatureSelection = bestFeatureSelectionModel.transform(normalizedXs)\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(\n",
    "        XsAfterFeatureSelection, \n",
    "        nonNulldataFrame[\"pCR (outcome)\"], \n",
    "        test_size=0.2,\n",
    "        random_state=1, \n",
    "        stratify=nonNulldataFrame[\"pCR (outcome)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if finalType == 1:\n",
    "    importantFeatures = bestFeatureSelectionModel.MB\n",
    "    for i in range(len(importantFeatures)):\n",
    "        importantFeatures[i] = importantFeatures[i].replace('Column','')\n",
    "    for i in range(len(importantFeatures)):\n",
    "        importantFeatures[i] = int(importantFeatures[i])\n",
    "    df = nonNulldataFrame.drop([\"pCR (outcome)\",\"RelapseFreeSurvival (outcome)\"], axis=1)\n",
    "    names = []\n",
    "    for i in range(len(importantFeatures)):\n",
    "        names.append(df.columns[importantFeatures[i]])\n",
    "    print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PgR', 0.16426829268292695), ('Age', 0.13048780487804887), ('ER', 0.11969512195121959), ('ChemoGrade', 0.09908536585365861), ('HistologyType', 0.09567073170731714), ('HER2', 0.07951219512195128), ('TrippleNegative', 0.07951219512195128), ('LNStatus', 0.07402439024390249), ('original_glcm_JointEnergy', 0.06214515405049756), ('original_glcm_JointEntropy', 0.061067857141104055), ('original_gldm_GrayLevelVariance', 0.060727239267103404), ('original_firstorder_Uniformity', 0.060727239229258906), ('original_glcm_SumEntropy', 0.05936436702734414), ('original_glcm_SumSquares', 0.05859417430939015), ('original_firstorder_Entropy', 0.057576657894910316), ('original_glcm_DifferenceVariance', 0.05504132601333934), ('original_glcm_ClusterProminence', 0.05487378928471993), ('original_glrlm_RunPercentage', 0.05434039730092), ('original_ngtdm_Complexity', 0.054055533438390375), ('original_glcm_MaximumProbability', 0.05377694409213456), ('original_glcm_ClusterTendency', 0.05370798783462379), ('original_glcm_DifferenceEntropy', 0.05278321906950188), ('original_glcm_ClusterShade', 0.05277147454830212), ('original_glcm_Idmn', 0.05060020514970654), ('original_glcm_Id', 0.050600205125107454), ('original_glcm_Idm', 0.050600205125107454), ('original_glcm_Contrast', 0.05060020511874212), ('original_glcm_DifferenceAverage', 0.05060020511874212), ('original_glcm_InverseVariance', 0.05060020511874212), ('original_glcm_Idn', 0.05060020506372805), ('original_glszm_HighGrayLevelZoneEmphasis', 0.04903250248620002), ('original_glszm_LowGrayLevelZoneEmphasis', 0.049032502481063646), ('original_shape_Maximum2DDiameterSlice', 0.048436210818020964), ('original_gldm_LowGrayLevelEmphasis', 0.04836459890371593), ('original_gldm_HighGrayLevelEmphasis', 0.04836459887740608), ('original_glcm_Autocorrelation', 0.04750749959747113), ('original_gldm_LargeDependenceEmphasis', 0.04746243220710246), ('original_glszm_ZoneEntropy', 0.04714580000960567), ('original_glrlm_RunLengthNonUniformityNormalized', 0.04648574879290657), ('original_shape_SurfaceArea', 0.04645278285684135), ('original_glrlm_GrayLevelNonUniformity', 0.04642961405382734), ('original_glcm_JointAverage', 0.04549184969146144), ('original_glcm_SumAverage', 0.04549184966169022), ('original_firstorder_Range', 0.045350350962258014), ('original_gldm_DependenceVariance', 0.043548926479431975), ('original_gldm_LargeDependenceHighGrayLevelEmphasis', 0.0434870603291372), ('original_glszm_SizeZoneNonUniformityNormalized', 0.04188980572796443), ('original_shape_MajorAxisLength', 0.041512590135966414), ('original_gldm_DependenceEntropy', 0.04094323873811111), ('original_ngtdm_Contrast', 0.04041594235493243), ('original_glcm_Imc2', 0.04032992096839808), ('original_glszm_GrayLevelNonUniformityNormalized', 0.040120556088170785), ('original_glszm_GrayLevelVariance', 0.040120556072926854), ('original_glrlm_RunLengthNonUniformity', 0.03987174041901852), ('original_shape_Maximum3DDiameter', 0.03849455959546648), ('original_glszm_SmallAreaLowGrayLevelEmphasis', 0.03706373772911011), ('original_glszm_SmallAreaEmphasis', 0.03595500880036594), ('original_glrlm_ShortRunHighGrayLevelEmphasis', 0.03506077580431123), ('original_glrlm_ShortRunEmphasis', 0.034876725773198565), ('original_shape_Sphericity', 0.03482675247080335), ('original_glszm_SmallAreaHighGrayLevelEmphasis', 0.034227542683810265), ('original_firstorder_10Percentile', 0.03357807574254257), ('original_shape_Maximum2DDiameterColumn', 0.03344926307174013), ('original_glrlm_LowGrayLevelRunEmphasis', 0.030804342159096453), ('original_glrlm_HighGrayLevelRunEmphasis', 0.03080434215458767), ('original_ngtdm_Busyness', 0.030114613523972954), ('original_firstorder_InterquartileRange', 0.030088114862591664), ('original_shape_MeshVolume', 0.030025410010801473), ('original_shape_VoxelVolume', 0.02998607269134177), ('original_firstorder_Maximum', 0.029840943749559812), ('original_firstorder_MeanAbsoluteDeviation', 0.0294614605588756), ('original_gldm_GrayLevelNonUniformity', 0.029311948768240965), ('original_firstorder_RobustMeanAbsoluteDeviation', 0.02890962824307917), ('Proliferation', 0.028841463414634155), ('original_glrlm_ShortRunLowGrayLevelEmphasis', 0.028619744014667745), ('original_firstorder_Variance', 0.028036974647605174), ('original_glrlm_GrayLevelVariance', 0.026993673251924862), ('original_glrlm_GrayLevelNonUniformityNormalized', 0.026993673245046017), ('original_shape_LeastAxisLength', 0.026326369526075824), ('original_glrlm_RunEntropy', 0.026273381434596847), ('original_shape_SurfaceVolumeRatio', 0.02581319924376412), ('original_shape_MinorAxisLength', 0.024287698170352232), ('original_shape_Maximum2DDiameterRow', 0.023007681321776587), ('original_gldm_LargeDependenceLowGrayLevelEmphasis', 0.022786129749628445), ('original_firstorder_Mean', 0.021355078493439476), ('original_firstorder_Skewness', 0.020847343308319423), ('original_firstorder_Minimum', 0.02006674415350507), ('original_gldm_DependenceNonUniformityNormalized', 0.019870686323739725), ('original_firstorder_90Percentile', 0.019709673166294923), ('original_shape_Flatness', 0.019064586318510622), ('original_firstorder_Median', 0.017318212727713313), ('original_ngtdm_Coarseness', 0.016996269482075863), ('original_gldm_SmallDependenceLowGrayLevelEmphasis', 0.014966285942546866), ('original_firstorder_Energy', 0.014955860063437526), ('original_firstorder_TotalEnergy', 0.014955860063437526), ('original_firstorder_RootMeanSquared', 0.014650723349126371), ('original_gldm_DependenceNonUniformity', 0.01423494749360697), ('original_glrlm_LongRunEmphasis', 0.013873321571470474), ('TumourStage', 0.013635243297653489), ('original_glrlm_LongRunHighGrayLevelEmphasis', 0.013333431693360083), ('original_ngtdm_Strength', 0.013331734663710555), ('original_glrlm_RunVariance', 0.010409576346174749), ('original_gldm_SmallDependenceEmphasis', 0.010149508927572866), ('original_glcm_Correlation', 0.009705393120098946), ('original_glcm_MCC', 0.009247864364617466), ('original_glrlm_LongRunLowGrayLevelEmphasis', 0.008318008308021358), ('original_gldm_SmallDependenceHighGrayLevelEmphasis', 0.006005697982864325), ('original_glszm_ZonePercentage', 0.0056513153566875975), ('original_glszm_LargeAreaLowGrayLevelEmphasis', 0.0027645356087597534), ('original_glcm_Imc1', 0.0018985102516688424), ('original_glszm_LargeAreaHighGrayLevelEmphasis', 0.00024015623641669717), ('original_shape_Elongation', -0.0004353423237814032), ('original_glszm_SizeZoneNonUniformity', -0.0005798641672438041), ('original_glszm_LargeAreaEmphasis', -0.0025623021102767134), ('original_glszm_ZoneVariance', -0.002997141123174781), ('original_glszm_GrayLevelNonUniformity', -0.007675196667029613), ('original_firstorder_Kurtosis', -0.009465672284476196)]\n"
     ]
    }
   ],
   "source": [
    "if finalType == 0:\n",
    "    class_data = dataFrame.drop([\"pCR (outcome)\",\"RelapseFreeSurvival (outcome)\"], axis=1).columns.values\n",
    "    dicti = dict(zip(class_data,bestFeatureSelectionModel.feature_importances_))\n",
    "    important_feat = sorted(dicti.items(),key = lambda x:x[1],reverse = True)\n",
    "    print(important_feat)\n",
    "    names = []\n",
    "    for i in range(len(Xs_train[0])):\n",
    "        names.append(important_feat[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if finalType == 2:\n",
    "    df = nonNulldataFrame.drop([\"pCR (outcome)\",\"RelapseFreeSurvival (outcome)\"], axis=1)\n",
    "    names = []\n",
    "    importantFeatures = bestFeatureSelectionModel.get_support(indices=True)\n",
    "    for i in range(len(importantFeatures)):\n",
    "        names.append(df.columns[importantFeatures[i]])\n",
    "    print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best feature num: 71\n",
      "<bound method BaseEstimator.get_params of ReliefF(n_features_to_select=71, n_jobs=-1, n_neighbors=41)>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %d\"  % (\"best feature num\",len(Xs_train[0])))\n",
    "bestFeatureNum =len(Xs_train[0])\n",
    "print(bestFeatureSelectionModel.get_params)\n",
    "print(finalType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer K:  1\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  2\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.92%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  3\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  4\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.92%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  5\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.92%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 68.63%\n",
      "outer K:  6\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 63.46%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  7\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  8\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  9\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  10\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  11\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 59.62%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  12\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.85%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  13\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  14\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 68.63%\n",
      "outer K:  15\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  16\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  17\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.92%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  18\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  19\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 71.15%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  20\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  21\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 82.35%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  22\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.85%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  23\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.92%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  24\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  25\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      " Classification accuracy: 70.59%\n",
      "Best Model Classification accuracy: 76.25%\n",
      "{'solver': 'sgd', 'random_state': 26, 'learning_rate': 'constant', 'hidden_layer_sizes': 22, 'alpha': 0.01, 'activation': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "\n",
    "\n",
    "bestScore = 0\n",
    "bestModel = None\n",
    "outerLoop = KFold(n_splits=5)\n",
    "innerLoop = KFold(n_splits=5)\n",
    "\n",
    "outerK = 0\n",
    "for i in range(2):\n",
    "    for outter_train_index, outter_test_index in outerLoop.split(Xs_train):\n",
    "\n",
    "        print(\"outer K: \",(outerK+1))\n",
    "        outerK += 1\n",
    "        X_total_train, X_total_test = np.array(Xs_train)[outter_train_index], np.array(Xs_train)[outter_test_index]\n",
    "        y_total_train, y_total_test = np.array(y_train)[outter_train_index], np.array(y_train)[outter_test_index]\n",
    "        innerBestScore = 0\n",
    "        potentialBestModel = None\n",
    "        innerK = 0\n",
    "        for inner_train_index, inner_validation_index in innerLoop.split(X_total_train):\n",
    "            print(\"innerK: \",(innerK+1))\n",
    "            X_inner_train, X_validation = np.array(X_total_train)[inner_train_index], np.array(X_total_train)[inner_validation_index]\n",
    "            y_inner_train, y_validation = np.array(y_total_train)[inner_train_index], np.array(y_total_train)[inner_validation_index]\n",
    "\n",
    "            param_mlpc = {   \n",
    "                            'hidden_layer_sizes' : [(random.randint(100,150),random.randint(50, 70),random.randint(10, 30)),\n",
    "                                                    (random.randint(50,70),random.randint(10,30)),\n",
    "                                                    (random.randint(10, 30))],\n",
    "                            'activation' : ['identity','logistic','tanh','relu'],\n",
    "                            \"random_state\" : range(0, 50),\n",
    "                            'alpha' : [0.0001, 0.001, 0.01, 0.1],\n",
    "                            'solver' : ['sgd','adam'],\n",
    "                            'learning_rate' : ['constant','invscaling'],\n",
    "                            \n",
    "                            }\n",
    "            #find the best parameter tunning\n",
    "            #to be implemented\n",
    "\n",
    "            grid = RandomizedSearchCV(MLPClassifier(max_iter= 500),param_mlpc,refit=True,verbose=1,n_iter= 10)\n",
    "            model = grid.fit(X_inner_train, y_inner_train)\n",
    "            model.predict(X_validation)\n",
    "            innerScore = metrics.accuracy_score(y_validation, model.predict(X_validation))\n",
    "            print(\" %s: %.2f%%\" % (\"Classification accuracy\", innerScore * 100))\n",
    "            if(innerScore > innerBestScore):\n",
    "                innerBestScore = innerScore\n",
    "                potentialBestModel = model\n",
    "            innerK += 1\n",
    "\n",
    "        #fit the model using the best parameter\n",
    "        y_pred = potentialBestModel.predict(X_total_test)\n",
    "        score = metrics.accuracy_score(y_total_test, y_pred)\n",
    "\n",
    "        #keep a reference of the best model for further usage\n",
    "        if(score > bestScore):\n",
    "            #print(bestModel.best_params_)\n",
    "            bestScore = score\n",
    "            bestModel = potentialBestModel\n",
    "\n",
    "testResult = bestModel.predict(Xs_test)\n",
    "print(\"%s: %.2f%%\" % (\"Best Model Classification accuracy\", (metrics.accuracy_score(y_test, testResult))*100))\n",
    "print(bestModel.best_params_)\n",
    "if (metrics.accuracy_score(y_test, testResult)) > performance:\n",
    "    performance = metrics.accuracy_score(y_test, testResult)\n",
    "    bestModelOverAll = bestModel\n",
    "    isKeras = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer K:  1\n",
      "WARNING:tensorflow:From c:\\Users\\27571\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\27571\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  2\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  3\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  4\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  5\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  6\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  7\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  8\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  9\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  10\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  11\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  12\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  13\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  14\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  15\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  16\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  17\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  18\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  19\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  20\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  21\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  22\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  23\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  24\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "outer K:  25\n",
      "innerK:  1\n",
      "innerK:  2\n",
      "innerK:  3\n",
      "innerK:  4\n",
      "innerK:  5\n",
      "WARNING:tensorflow:From c:\\Users\\27571\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\27571\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Best Model Classification accuracy: 78.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "bestScore = 0\n",
    "outerLoop = KFold(n_splits=5)\n",
    "innerLoop = KFold(n_splits=5)\n",
    "\n",
    "outerK = 0\n",
    "for i in range(3):\n",
    "    for outter_train_index, outter_test_index in outerLoop.split(Xs_train):\n",
    "\n",
    "        print(\"outer K: \",(outerK+1))\n",
    "        outerK += 1\n",
    "        X_total_train, X_total_test = np.array(Xs_train)[outter_train_index], np.array(Xs_train)[outter_test_index]\n",
    "        y_total_train, y_total_test = np.array(y_train)[outter_train_index], np.array(y_train)[outter_test_index]\n",
    "        \n",
    "        activationTypes = ['relu', 'sigmoid', 'softmax','softplus','softsign','tanh','selu','elu','exponential']\n",
    "\n",
    "        ann=keras.models.Sequential()\n",
    "        ann.add(keras.layers.Dense(random.randint(100,150), input_dim=bestFeatureNum,activation=activationTypes[random.randint(0,8)]))\n",
    "        ann.add(keras.layers.Dense(random.randint(30,60),activation=activationTypes[random.randint(0,8)]))\n",
    "        ann.add(keras.layers.Dense(random.randint(5,15),activation=activationTypes[random.randint(0,8)]))\n",
    "        ann.add(keras.layers.Dense(1,activation=activationTypes[random.randint(0,8)]))\n",
    "\n",
    "        lossTypes = ['binary_crossentropy', 'hinge']\n",
    "        optimizerType = ['sgd', 'adam']\n",
    "        ann.compile(loss=lossTypes[random.randint(0,1)], optimizer=optimizerType[random.randint(0,1)], metrics=[\"accuracy\"])\n",
    "        # save the initial weight for initilise new models in cross validation\n",
    "        ann.save_weights('model.h5')\n",
    "\n",
    "        innerK = 0\n",
    "        for inner_train_index, inner_validation_index in innerLoop.split(X_total_train):\n",
    "            print(\"innerK: \",(innerK+1))\n",
    "            X_inner_train, X_validation = np.array(X_total_train)[inner_train_index], np.array(X_total_train)[inner_validation_index]\n",
    "            y_inner_train, y_validation = np.array(y_total_train)[inner_train_index], np.array(y_total_train)[inner_validation_index]\n",
    "            ann.load_weights('model.h5')\n",
    "            model = ann.fit(np.array(X_inner_train),\n",
    "                            np.array(y_inner_train), \n",
    "                            epochs = 500, \n",
    "                            validation_data=(np.array(X_validation),np.array(y_validation)),\n",
    "                            verbose= 0)\n",
    "            scores = ann.evaluate(np.array(X_total_test),np.array(y_total_test), verbose=0)\n",
    "            #keep a reference of the best model for further usage\n",
    "            if(scores[1] > bestScore):\n",
    "                #print(bestModel.best_params_)\n",
    "                bestScore = scores[1]\n",
    "                ann.save('best.h5')\n",
    "            innerK += 1\n",
    "\n",
    "testResults = keras.models.load_model('best.h5').evaluate(np.array(Xs_test),np.array(y_test), verbose=0)\n",
    "print(\"%s: %.2f%%\" % (\"Best Model Classification accuracy\", testResults[1]*100))\n",
    "\n",
    "if (metrics.accuracy_score(y_test, testResult)) > performance:\n",
    "    performance = metrics.accuracy_score(y_test, testResult)\n",
    "    bestModelOverAll = keras.models.load_model('best.h5')\n",
    "    isKeras = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer K:  1\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  2\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  3\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  4\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  5\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "\n",
    "\n",
    "bestScore = 0\n",
    "bestModel = None\n",
    "outerLoop = KFold(n_splits=5)\n",
    "innerLoop = KFold(n_splits=5)\n",
    "\n",
    "outerK = 0\n",
    "for i in range(3):\n",
    "    for outter_train_index, outter_test_index in outerLoop.split(Xs_train):\n",
    "\n",
    "        print(\"outer K: \",(outerK+1))\n",
    "        outerK += 1\n",
    "        X_total_train, X_total_test = np.array(Xs_train)[outter_train_index], np.array(Xs_train)[outter_test_index]\n",
    "        y_total_train, y_total_test = np.array(y_train)[outter_train_index], np.array(y_train)[outter_test_index]\n",
    "        innerBestScore = 0\n",
    "        potentialBestModel = None\n",
    "        innerK = 0\n",
    "        for inner_train_index, inner_validation_index in innerLoop.split(X_total_train):\n",
    "            print(\"innerK: \",(innerK+1))\n",
    "            X_inner_train, X_validation = np.array(X_total_train)[inner_train_index], np.array(X_total_train)[inner_validation_index]\n",
    "            y_inner_train, y_validation = np.array(y_total_train)[inner_train_index], np.array(y_total_train)[inner_validation_index]\n",
    "\n",
    "            param_svc = {   'C': np.logspace(-2, 10, 13),\n",
    "                            #'degree': range(10,50),\n",
    "                            'gamma': np.logspace(-9, 3, 13),\n",
    "                            'shrinking' : [True, False],\n",
    "                            \"random_state\" : range(0, 50)\n",
    "                            }\n",
    "            #find the best parameter tunning\n",
    "            #to be implemented\n",
    "\n",
    "            grid = RandomizedSearchCV(SVC(),param_svc,refit=True,verbose=1,n_iter= 50)\n",
    "            model = grid.fit(X_inner_train, y_inner_train)\n",
    "            model.predict(X_validation)\n",
    "            innerScore = metrics.accuracy_score(y_validation, model.predict(X_validation))\n",
    "            print(\" %s: %.2f%%\" % (\"Classification accuracy\", innerScore * 100))\n",
    "            if(innerScore > innerBestScore):\n",
    "                innerBestScore = innerScore\n",
    "                potentialBestModel = model\n",
    "            innerK += 1\n",
    "\n",
    "        #fit the model using the best parameter\n",
    "        y_pred = potentialBestModel.predict(X_total_test)\n",
    "        score = metrics.accuracy_score(y_total_test, y_pred)\n",
    "\n",
    "        #keep a reference of the best model for further usage\n",
    "        if(score > bestScore):\n",
    "            #print(bestModel.best_params_)\n",
    "            bestScore = score\n",
    "            bestModel = potentialBestModel\n",
    "\n",
    "\n",
    "testResult = bestModel.predict(Xs_test)\n",
    "print(\"%s: %.2f%%\" % (\"Best Model Classification accuracy\", (metrics.accuracy_score(y_test, testResult))*100))\n",
    "print(bestModel.best_params_)\n",
    "if (metrics.accuracy_score(y_test, testResult)) > performance:\n",
    "    performance = metrics.accuracy_score(y_test, testResult)\n",
    "    bestModelOverAll = bestModel\n",
    "    isKeras = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer K:  1\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 65.38%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  2\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  3\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  4\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  5\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  6\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 65.38%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  7\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 71.15%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  8\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  9\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  10\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 82.35%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  11\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  12\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  13\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  14\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  15\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  16\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 65.38%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  17\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "outer K:  18\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  19\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  20\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 66.67%\n",
      "outer K:  21\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 65.38%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "outer K:  22\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "outer K:  23\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  24\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  25\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " Classification accuracy: 70.59%\n",
      "Best Model Classification accuracy: 76.25%\n",
      "{'warm_start': True, 'random_state': 10, 'n_estimators': 408, 'min_samples_split': 7, 'max_features': 'log2', 'max_depth': 3, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import random\n",
    "\n",
    "\n",
    "bestScore = 0\n",
    "bestModel = None\n",
    "outerLoop = KFold(n_splits=5)\n",
    "innerLoop = KFold(n_splits=5)\n",
    "\n",
    "outerK = 0\n",
    "for i in range(5):\n",
    "    for outter_train_index, outter_test_index in outerLoop.split(Xs_train):\n",
    "\n",
    "        print(\"outer K: \",(outerK+1))\n",
    "        outerK += 1\n",
    "        X_total_train, X_total_test = np.array(Xs_train)[outter_train_index], np.array(Xs_train)[outter_test_index]\n",
    "        y_total_train, y_total_test = np.array(y_train)[outter_train_index], np.array(y_train)[outter_test_index]\n",
    "        innerBestScore = 0\n",
    "        potentialBestModel = None\n",
    "        innerK = 0\n",
    "        for inner_train_index, inner_validation_index in innerLoop.split(X_total_train):\n",
    "            print(\"innerK: \",(innerK+1))\n",
    "            X_inner_train, X_validation = np.array(X_total_train)[inner_train_index], np.array(X_total_train)[inner_validation_index]\n",
    "            y_inner_train, y_validation = np.array(y_total_train)[inner_train_index], np.array(y_total_train)[inner_validation_index]\n",
    "\n",
    "            param_random_forest = {   \"n_estimators\" : range(100, 500),\n",
    "                                    \"criterion\" : [\"gini\",\"entropy\"],\n",
    "                                    \"max_depth\" : range(3, 25),\n",
    "                                    \"min_samples_split\" : range(2, 10),\n",
    "                                    \"max_features\" : [\"auto\", \"sqrt\", \"log2\", None],\n",
    "                                    \"random_state\" : range(0, 50),\n",
    "                                    \"warm_start\" : [True, False]\n",
    "                                    }\n",
    "            #find the best parameter tunning\n",
    "            #to be implemented\n",
    "\n",
    "            grid = RandomizedSearchCV(RandomForestClassifier(ccp_alpha= random.uniform(0.012,0.019)),param_random_forest,refit=True,verbose=1,n_iter= 2)\n",
    "            model = grid.fit(X_inner_train, y_inner_train)\n",
    "            model.predict(X_validation)\n",
    "            innerScore = metrics.accuracy_score(y_validation, model.predict(X_validation))\n",
    "            print(\" %s: %.2f%%\" % (\"Classification accuracy\", innerScore * 100))\n",
    "            if(innerScore > innerBestScore):\n",
    "                innerBestScore = innerScore\n",
    "                potentialBestModel = model\n",
    "            innerK += 1\n",
    "\n",
    "        #fit the model using the best parameter\n",
    "        y_pred = potentialBestModel.predict(X_total_test)\n",
    "        score = metrics.accuracy_score(y_total_test, y_pred)\n",
    "\n",
    "        #keep a reference of the best model for further usage\n",
    "        if(score > bestScore):\n",
    "            bestScore = score\n",
    "            bestModel = potentialBestModel\n",
    "\n",
    "\n",
    "testResult = bestModel.predict(Xs_test)\n",
    "print(\"%s: %.2f%%\" % (\"Best Model Classification accuracy\", (metrics.accuracy_score(y_test, testResult))*100))\n",
    "print(bestModel.best_params_)\n",
    "\n",
    "if (metrics.accuracy_score(y_test, testResult)) > performance:\n",
    "    performance = metrics.accuracy_score(y_test, testResult)\n",
    "    bestModelOverAll = bestModel\n",
    "    isKeras = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer K:  1\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 57.69%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 54.90%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "outer K:  2\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 60.78%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "outer K:  3\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 59.62%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 54.90%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  4\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "outer K:  5\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 54.90%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "outer K:  6\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 71.15%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "outer K:  7\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 75.00%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 64.71%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 78.43%\n",
      "outer K:  8\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 56.86%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 60.78%\n",
      "outer K:  9\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  10\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 78.43%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "outer K:  11\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 59.62%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  12\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 76.92%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 54.90%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "outer K:  13\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 64.71%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  14\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 71.15%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 54.90%\n",
      "outer K:  15\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  16\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 55.77%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  17\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 78.85%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 64.71%\n",
      "outer K:  18\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 60.78%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  19\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  20\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 54.90%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "outer K:  21\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 61.54%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 64.71%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 74.51%\n",
      "outer K:  22\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 73.08%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 82.35%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 76.47%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 72.55%\n",
      "outer K:  23\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 71.15%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 58.82%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 64.71%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 62.75%\n",
      "outer K:  24\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 69.23%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 74.51%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 56.86%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 70.59%\n",
      "outer K:  25\n",
      "innerK:  1\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 67.31%\n",
      "innerK:  2\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 80.39%\n",
      "innerK:  3\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 66.67%\n",
      "innerK:  4\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "innerK:  5\n",
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      " Classification accuracy: 68.63%\n",
      "Best Model Classification accuracy: 76.25%\n",
      "{'splitter': 'random', 'max_features': 'log2', 'max_depth': 5, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "bestScore = 0\n",
    "bestModel = None\n",
    "outerLoop = KFold(n_splits=5)\n",
    "innerLoop = KFold(n_splits=5)\n",
    "\n",
    "outerK = 0\n",
    "for i in range(5):\n",
    "    for outter_train_index, outter_test_index in outerLoop.split(Xs_train):\n",
    "\n",
    "        print(\"outer K: \",(outerK+1))\n",
    "        outerK += 1\n",
    "        X_total_train, X_total_test = np.array(Xs_train)[outter_train_index], np.array(Xs_train)[outter_test_index]\n",
    "        y_total_train, y_total_test = np.array(y_train)[outter_train_index], np.array(y_train)[outter_test_index]\n",
    "        innerBestScore = 0\n",
    "        potentialBestModel = None\n",
    "        innerK = 0\n",
    "        for inner_train_index, inner_validation_index in innerLoop.split(X_total_train):\n",
    "            print(\"innerK: \",(innerK+1))\n",
    "            X_inner_train, X_validation = np.array(X_total_train)[inner_train_index], np.array(X_total_train)[inner_validation_index]\n",
    "            y_inner_train, y_validation = np.array(y_total_train)[inner_train_index], np.array(y_total_train)[inner_validation_index]\n",
    "\n",
    "            param_dision_tree = {   \"criterion\" : [\"gini\",\"entropy\"],\n",
    "                                    \"splitter\" : [\"best\", \"random\"],\n",
    "                                    \"max_depth\" : range(5,200),\n",
    "                                    \"max_features\" : [\"auto\", \"sqrt\", \"log2\", None]}\n",
    "            #find the best parameter tunning\n",
    "            #to be implemented\n",
    "\n",
    "            grid = RandomizedSearchCV(DecisionTreeClassifier(),param_dision_tree,refit=True,verbose=1,n_iter= 70)\n",
    "            model = grid.fit(X_inner_train, y_inner_train)\n",
    "            model.predict(X_validation)\n",
    "            innerScore = metrics.accuracy_score(y_validation, model.predict(X_validation))\n",
    "            print(\" %s: %.2f%%\" % (\"Classification accuracy\", innerScore * 100))\n",
    "            if(innerScore > innerBestScore):\n",
    "                innerBestScore = innerScore\n",
    "                potentialBestModel = model\n",
    "            innerK += 1\n",
    "\n",
    "        #fit the model using the best parameter\n",
    "        y_pred = potentialBestModel.predict(X_total_test)\n",
    "        score = metrics.accuracy_score(y_total_test, y_pred)\n",
    "\n",
    "        #keep a reference of the best model for further usage\n",
    "        if(score > bestScore):\n",
    "            bestScore = score\n",
    "            bestModel = potentialBestModel\n",
    "\n",
    "\n",
    "testResult = bestModel.predict(Xs_test)\n",
    "print(\"%s: %.2f%%\" % (\"Best Model Classification accuracy\", (metrics.accuracy_score(y_test, testResult))*100))\n",
    "print(bestModel.best_params_)\n",
    "if (metrics.accuracy_score(y_test, testResult)) > performance:\n",
    "    performance = metrics.accuracy_score(y_test, testResult)\n",
    "    bestModelOverAll = bestModel\n",
    "    isKeras = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFrame = pd.read_excel(\"testDatasetExample.xls\")\n",
    "testFrame.drop(\"ID\", axis=1 ,inplace=True)\n",
    "testFrame = testFrame[names]\n",
    "scaledFeatures = standardScaler.fit_transform(testFrame.values)\n",
    "scaledFeaturesDF = pd.DataFrame(scaledFeatures, columns=testFrame.columns)\n",
    "scaledFeaturesDF.head()\n",
    "\n",
    "trainFrame = nonNulldataFrame[names]\n",
    "scaledTrainFeature = standardScaler.fit_transform(trainFrame.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isKeras == True:\n",
    "    Y_PRED = bestModelOverAll.predict_classes(np.array(scaledFeatures), verbose=0)\n",
    "    for i in range(len(Y_PRED)):\n",
    "        print(Y_PRED[i])\n",
    "else:\n",
    "    Y_PRED = bestModelOverAll.predict(scaledFeatures)\n",
    "    for i in range(len(Y_PRED)):\n",
    "        print(Y_PRED[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "if isKeras == True:\n",
    "    Y_PRED = bestModelOverAll.predict_classes(np.array(scaledFeatures), verbose=0)\n",
    "    for i in range(len(Y_PRED)):\n",
    "        print(Y_PRED[i])\n",
    "else:\n",
    "    bestModelOverAll.fit(scaledTrainFeature, nonNulldataFrame[\"pCR (outcome)\"])\n",
    "    Y_PRED = bestModelOverAll.predict(scaledFeatures)\n",
    "    for i in range(len(Y_PRED)):\n",
    "        print(Y_PRED[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "if isKeras == True:\n",
    "    Y_PRED = bestModelOverAll.predict_classes(np.array(scaledFeatures), verbose=0)\n",
    "    for i in range(len(Y_PRED)):\n",
    "        print(Y_PRED[i])\n",
    "else:\n",
    "    bestModelOverAll.fit(scaledTrainFeature, nonNulldataFrame[\"pCR (outcome)\"].values)\n",
    "    Y_PRED = bestModelOverAll.predict(scaledFeatures)\n",
    "    for i in range(len(Y_PRED)):\n",
    "        print(Y_PRED[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7625\n"
     ]
    }
   ],
   "source": [
    "print(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mle_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f86663af17eddc6bc27b09c33319d830f1e8c8276d7c98046cf3c31540c86e98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
